# Материалы по машинному обучению

[Шпаргалки по курсам Стенфорда CS 221 (AI), 229 (ML), 230 (DL)](https://alexandrparkhomenko.github.io/stanford/cs-221/reflex-models/index.html)

[Книга онлайн: Computational and Inferential Thinking: The Foundations of Data Science](https://inferentialthinking.com/chapters/intro.html)



## Machine Learning

### Метод наименьших квадратов (МНК, The Method of Least Squares)
[Хорошие картинки](https://inferentialthinking.com/chapters/15/3/Method_of_Least_Squares.html)

## Deep Learning

### Геометрическая интерпретация работы нейронов
[Примеры с картинками](http://synset.com/ai/ru/nn/NeuralNet_01_Intro.html)
[Интерактивное демо](http://synset.com/ai/ru/nn/NeuroNet2D.html)

### XOR

[Задача XOR на нейронке с 3 нейронами](https://towardsdatascience.com/implementing-the-xor-gate-using-backpropagation-in-neural-networks-c1f255b4f20d)
(внимание на график в конце, количество эпох)


[Визуализация некоторых задач типа XOR на нейронках - интерактивное демо](https://playground.tensorflow.org/)

### Обучение сети

#### Градиентный спуск

#### Матричные производные

#### Правило цепочки

#### Функции активации
[Сигмоида - интерактивное демо](https://www.desmos.com/calculator/suezuqyfak)
[Сигмоида+следующий нейрон - интерактивное демо](https://www.desmos.com/calculator/vtcgs6wt62)
[Сумма сигмоид как приближение некоторой функции - интерактивное демо](https://www.desmos.com/calculator/foellcf2py)

#### Функции потерь

#### Обратное распространение ошибки (Backpropagation)

[Пример расчета на простой сети с двумя слоями](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)

#### Переобучение

#### Регуляризация

#### Вымывание и взрыв градиента

#### Батчнорм

#### Дропаут
