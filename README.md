# Материалы по машинному обучению

[Шпаргалки по курсам Стенфорда CS 221 (AI), 229 (ML), 230 (DL)](https://alexandrparkhomenko.github.io/stanford/cs-221/reflex-models/index.html)

[Книга онлайн: Computational and Inferential Thinking: The Foundations of Data Science](https://inferentialthinking.com/chapters/intro.html)

[Курс Нейронные сети и компьютерное зрение от Samsung на Степике](https://stepik.org/course/50352/syllabus) + [Презентации к курсу](https://github.com/RomanovMikeV/deep-learning-lectures)


## Machine Learning

### Метод наименьших квадратов (МНК, The Method of Least Squares)
[Хорошие картинки](https://inferentialthinking.com/chapters/15/3/Method_of_Least_Squares.html)

[МНК: вывод решения](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2)

## Deep Learning

[Видео объяснение работы нейронных сетей (рус. sub)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

### Геометрическая интерпретация работы нейронов
[Примеры с картинками](http://synset.com/ai/ru/nn/NeuralNet_01_Intro.html) +
[Интерактивное демо](http://synset.com/ai/ru/nn/NeuroNet2D.html)

[Геометрия машинного обучения. Разделяющие гиперплоскости или в чём геометрический смысл линейной комбинации? (habr)](https://habr.com/ru/post/324736/)

### XOR

[Задача XOR на нейронке с 3 нейронами](https://towardsdatascience.com/implementing-the-xor-gate-using-backpropagation-in-neural-networks-c1f255b4f20d)
(внимание на график в конце, количество эпох)


[Визуализация некоторых задач типа XOR на нейронках - интерактивное демо](https://playground.tensorflow.org/)

### Обучение сети

#### Градиентный спуск

#### Матричные производные
[Семинар 2: Матрично-векторное дифференцирование](http://www.machinelearning.ru/wiki/images/5/50/MOMO17_Seminar2.pdf)

[Видео-пример](https://www.youtube.com/watch?v=e73033jZTCI)

[Заметки по матричным вычислениям и нормальному распределению](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)

[Дифференцирование матрицы](http://nabatchikov.com/blog/view/matrix_der), [Дифференцирование матрицы: разбираем формулы](http://nabatchikov.com/blog/view/matrix_der_2)

#### Правило цепочки

#### Функции активации 
[Сигмоида - интерактивное демо](https://www.desmos.com/calculator/suezuqyfak)

[Сигмоида+следующий нейрон - интерактивное демо](https://www.desmos.com/calculator/vtcgs6wt62)

[Сумма сигмоид как приближение некоторой функции - интерактивное демо](https://www.desmos.com/calculator/foellcf2py)

[Производная сигмоидной функции](https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e)

#### Функции потерь

#### Обратное распространение ошибки (Backpropagation)

[Пример расчета на простой сети с двумя слоями](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)

#### Переобучение

#### Регуляризация

#### Вымывание и взрыв градиента

#### Батчнорм

#### Дропаут

[]()
